{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergioRevu/Deeplearning_cf/blob/main/Copia_de_Deep_Learning_Clase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Deep Learning - Clase 3  üß†\n",
        "\n",
        "> **Descripci√≥n:** Cuaderno de contenidos (III) sobre introducci√≥n a _deep learning_ para el Bootcamp en DS con C√≥digo Facilito, 2023. <br>\n",
        "> **Autor:** [Rodolfo Ferro](https://github.com/RodolfoFerro) <br>\n",
        "> **Contacto:** [Twitter](https://twitter.com/rodo_ferro) / [Instagram](https://www.instagram.com/rodo_ferro/)\n",
        "\n",
        "\n",
        "## Contenido\n",
        "\n",
        "### Secci√≥n VII\n",
        "\n",
        "25. Refresher sobre ANNs\n",
        "    - Neuronas artificiales\n",
        "    - Entrenamiento\n",
        "26. ANNs con TensorFlow\n",
        "\n",
        "\n",
        "### Secci√≥n VIII\n",
        "\n",
        "27. Introducci√≥n a im√°genes\n",
        "28. Espacios de color\n",
        "29. Convoluciones & Pooling\n",
        "\n",
        "\n",
        "### Secci√≥n IX ‚Äì Tarea\n",
        "\n",
        "30. Redes convolucionales\n",
        "31. Clasificadores de im√°genes (LeNet5, etc.)\n",
        "32. Descripci√≥n del reto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Secci√≥n VII**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _Refresher_ sobre ANNs\n",
        "\n",
        "Veamos c√≥mo se puede entrenar una sola neurona para hacer una predicci√≥n.\n",
        "\n",
        "Para este problema construiremos un perceptr√≥n simple, como el propuesto por McCulloch & Pitts, usando la funci√≥n sigmoide.\n",
        "\n",
        "#### **Planteamiento del problema:**\n",
        "\n",
        "Queremos mostrarle a una neurona simple un conjunto de ejemplos para que pueda aprender c√≥mo se comporta una funci√≥n. El conjunto de ejemplos es el siguiente:\n",
        "\n",
        "- `(1, 0)` deber√≠a devolver `1`.\n",
        "- `(0, 1)` debe devolver `1`.\n",
        "- `(0, 0)` deber√≠a devolver `0`.\n",
        "\n",
        "Entonces, si ingresamos a la neurona el valor de `(1, 1)`, deber√≠a poder predecir el n√∫mero `1`.\n",
        "\n",
        "> ¬øPuedes adivinar la funci√≥n?\n",
        "\n",
        "#### ¬øQue necesitamos hacer?\n",
        "\n",
        "Programar y entrenar una neurona para hacer predicciones.\n",
        "\n",
        "En concreto, vamos a hacer lo siguiente:\n",
        "\n",
        "- Construir la clase y su constructor.\n",
        "- Definir la funci√≥n sigmoidea y su derivada\n",
        "- Definir el n√∫mero de √©pocas para el entrenamiento.\n",
        "- Resolver el problema y predecir el valor de la entrada deseada"
      ],
      "metadata": {
        "id": "2k4ZBY7drHpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class ArtificialNeuron():\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Class constructor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n : int\n",
        "            Input size.\n",
        "        \"\"\"\n",
        "\n",
        "        np.random.seed(123)\n",
        "        self.synaptic_weights = 2 * np.random.random((n, 1)) - 1\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        \"\"\"Sigmoid function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to sigmoid function.\n",
        "        \"\"\"\n",
        "\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the Sigmoid function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to evaluated sigmoid function.\"\"\"\n",
        "\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_output, iterations):\n",
        "        \"\"\"Training function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        training_inputs : list\n",
        "            List of features for training.\n",
        "        training_outputs : list\n",
        "            List of labels for training.\n",
        "        iterations : int\n",
        "            Number of iterations for training.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        history : list\n",
        "            A list containing the training history.\n",
        "        \"\"\"\n",
        "\n",
        "        history = []\n",
        "\n",
        "        for iteration in range(iterations):\n",
        "            output = self.predict(training_inputs)\n",
        "\n",
        "            # MSE\n",
        "            output_col = training_output.reshape((len(training_inputs), 1))\n",
        "            error = np.mean((output_col - output)**2)\n",
        "\n",
        "            adjustment = np.dot(training_inputs.T, error *\n",
        "                                self.__sigmoid_derivative(output))\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "            history.append(np.linalg.norm(error))\n",
        "\n",
        "        return history\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"Prediction function. Applies input function to inputs tensor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of inputs to apply sigmoid function.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__sigmoid(np.dot(inputs, self.synaptic_weights))"
      ],
      "metadata": {
        "id": "2NKx40hxqmo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generando las muestras\n",
        "\n",
        "Ahora podemos generar una lista de ejemplos basados en la descripci√≥n del problema."
      ],
      "metadata": {
        "id": "Ym_oEzbhxYKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training samples\n",
        "input_values = [(0, 1), (1, 0), (0, 0)]\n",
        "output_values = [1, 1, 0]\n",
        "\n",
        "training_inputs = np.array(input_values)\n",
        "training_output = np.array(output_values).T.reshape((3, 1))"
      ],
      "metadata": {
        "id": "BYW9aYSCxc1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando la neurona\n",
        "\n",
        "Para hacer el entrenamiento, primero definiremos una neurona. De forma predeterminada, contendr√° pesos aleatorios (ya que a√∫n no se ha entrenado):"
      ],
      "metadata": {
        "id": "DJUYV8H-xf7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the neuron\n",
        "neuron = ArtificialNeuron(2)\n",
        "print(\"Initial random weights:\")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "cThkcQGMxrX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO.\n",
        "# Modify the number of epochs to see how it performs.\n",
        "epochs = 10\n",
        "\n",
        "# We train the neuron a number of epochs:\n",
        "history = neuron.train(training_inputs, training_output, epochs)\n",
        "print(\"New synaptic weights after training: \")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "WnuCP6eHxtQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "x = np.arange(len(history))\n",
        "y = history\n",
        "\n",
        "plt.plot(x, y)"
      ],
      "metadata": {
        "id": "ZaEnp4kQ8Tjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Haciendo predicciones"
      ],
      "metadata": {
        "id": "7vPb5a65x0bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We predict to verify the performance:\n",
        "one_one = np.array((1, 1))\n",
        "print(\"Prediction for (1, 1): \")\n",
        "neuron.predict(one_one)"
      ],
      "metadata": {
        "id": "SrYM3ODKxwvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¬øC√≥mo se har√≠a esto con TensorFlow?**\n",
        "\n",
        "A continuaci√≥n recrearemos la misma neurona utilizando TensorFlow.\n",
        "\n",
        "Para esto, es necesario importar espec√≠ficamente los tipos de capas y modelos a utilizar.\n",
        "\n",
        "Analicemos un poco los detalles:"
      ],
      "metadata": {
        "id": "4PVmWpii8d2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(2,)))\n",
        "\n",
        "model.compile(loss='mse', optimizer='sgd')"
      ],
      "metadata": {
        "id": "3ZNP3xr_8gW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar el modelo, tambi√©n utilizaremos el m√©todo fit."
      ],
      "metadata": {
        "id": "Wx8Ck_UQuW5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model.fit(training_inputs, training_output, epochs=epochs, batch_size=1)"
      ],
      "metadata": {
        "id": "XNx8ciTBtOhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y de igual manera, podemos acceder al historial de entrenamiento."
      ],
      "metadata": {
        "id": "VO_N2CKluaLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "47Ku2lh5tcf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "x = np.arange(len(history.history['loss']))\n",
        "y = history.history['loss']\n",
        "\n",
        "plt.plot(x, y)"
      ],
      "metadata": {
        "id": "mG_jRYHqtYQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, ¬øesto c√≥mo escala a trabajar con redes que utilizan m√°s de una capa y m√°s de una neurona? Veamos.\n",
        "\n",
        "Para resolver un problema m√°s elaborado creando una red profunda, utilizaremos otros datos, los cuales cargaremos a continuaci√≥n.\n",
        "\n",
        "Los datos de Fashion MNIST est√°n disponibles directamente en la API de conjuntos de datos de `tf.keras`. Llamar a load_data en este objeto nos dar√° dos conjuntos con los valores de entrenamiento y prueba para los gr√°ficos que contienen las prendas y sus etiquetas."
      ],
      "metadata": {
        "id": "p0-n3OCyuoQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "WEV21IJJvqEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øC√≥mo se ven estos valores? Despleguemos una imagen de entrenamiento y una etiqueta de entrenamiento para saber."
      ],
      "metadata": {
        "id": "dfvbC_UewVZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "\n",
        "# Set index of image to be seen\n",
        "img_index = 3000 # 6000 -1\n",
        "\n",
        "# Plot image\n",
        "plt.imshow(training_images[img_index], cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", training_labels[img_index])\n",
        "print(\"Matrix:\", training_images[img_index])"
      ],
      "metadata": {
        "id": "m8lf8r2IvvQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notar√°s que todos los valores est√°n entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es m√°s f√°cil si transformamos los valores para tratar todos con valores entre 0 y 1."
      ],
      "metadata": {
        "id": "iNlmvxJ7wagU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "DA7Oh9Kov3we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que cada imagen es s√≥lo una matriz de 28x28 pixeles, s√≥lo con 1 canal de color."
      ],
      "metadata": {
        "id": "zURylVeHwpiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images[0].shape"
      ],
      "metadata": {
        "id": "wnwJemqkwoDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploraremos una segunda forma de crear un modelo secuencial."
      ],
      "metadata": {
        "id": "P8xbNplEwk8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # TODO. Dense -> 256, ReLU\n",
        "    # TODO. Dense -> 10, Softmax\n",
        "])"
      ],
      "metadata": {
        "id": "YufcQNV1u8S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilaremos y entrenaremos el modelo.\n",
        "\n",
        "Notemos que se utilizan otros par√°metros de compilaci√≥n."
      ],
      "metadata": {
        "id": "RNzAEV61xGKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.compile(\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "EizBOSZBw0gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.fit(training_images, training_labels, epochs=3)"
      ],
      "metadata": {
        "id": "gV-K8llnw3FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo incluye funciones que nos permiten evaluar sus resultados, utilizand el conjunto de datos de prueba."
      ],
      "metadata": {
        "id": "Il7cjCcjw-_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "4nSOGLDfw-gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos explorar los resultados del modelo al inferir individualmente con una sola imagen."
      ],
      "metadata": {
        "id": "N3iW_rSsvgwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_index = random.randint(0, 10000 - 1)\n",
        "\n",
        "plt.imshow(test_images[test_index], cmap='viridis')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "input_image = np.reshape(test_images[test_index], (1, 784))\n",
        "prediction = mlp_model.predict(np.expand_dims(input_image, axis=-1))\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "ESBpRrVTxUrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtpuj0PBqWYc"
      },
      "source": [
        "## **Secci√≥n VIII**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Convoluciones en im√°genes\n",
        "\n",
        "Exploremos qu√© sucede cuando barremos un filtro (kernel) sobre una imagen utilizando una convoluci√≥n.\n",
        "\n",
        "**Spoiler:** Intentemos escalar posibles resultados al tener muchos filtros dentro de una red neuronal."
      ],
      "metadata": {
        "id": "jJdHo17RAp4S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kdal-XjznDC"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# We load a sample image\n",
        "img = datasets.ascent()\n",
        "\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una copia de la imagen."
      ],
      "metadata": {
        "id": "Mbmr-R6Yyv36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformed = np.copy(img)\n",
        "size_x = img_transformed.shape[0]\n",
        "size_y = img_transformed.shape[1]"
      ],
      "metadata": {
        "id": "HNcuUIMjx_VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un filtro a utilizar."
      ],
      "metadata": {
        "id": "2nqmKQ94yxX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's experiment with different values\n",
        "\n",
        "filter = [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n",
        "# filter = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
        "# filter = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
        "\n",
        "weight = 1 / 8"
      ],
      "metadata": {
        "id": "ckPpotCCyIKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos las operaciones."
      ],
      "metadata": {
        "id": "B_jvUdSOyy_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(1, size_x - 1):\n",
        "  for y in range(1, size_y - 1):\n",
        "      convolution = 0.0\n",
        "      convolution = convolution + (img[x - 1, y - 1] * filter[0][0])\n",
        "      convolution = convolution + (img[x, y - 1] * filter[0][1])\n",
        "      convolution = convolution + (img[x + 1, y - 1] * filter[0][2])\n",
        "      convolution = convolution + (img[x - 1, y] * filter[1][0])\n",
        "      convolution = convolution + (img[x, y] * filter[1][1])\n",
        "      convolution = convolution + (img[x + 1, y] * filter[1][2])\n",
        "      convolution = convolution + (img[x - 1, y + 1] * filter[2][0])\n",
        "      convolution = convolution + (img[x, y + 1] * filter[2][1])\n",
        "      convolution = convolution + (img[x + 1, y + 1] * filter[2][2])\n",
        "      convolution = convolution * weight\n",
        "\n",
        "      if convolution < 0:\n",
        "        convolution = 0\n",
        "      if convolution > 255:\n",
        "        convolution = 255\n",
        "\n",
        "      img_transformed[x, y] = convolution"
      ],
      "metadata": {
        "id": "4LQtpt51yKvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos los resultados de convoluci√≥n."
      ],
      "metadata": {
        "id": "9W8I0UdWy1hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X4k5e1TnyM9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Pooling en im√°genes\n",
        "\n",
        "Exploremos qu√© sucede cuando reducimos la informaci√≥n de una imagen a trav√©s de pooling.\n"
      ],
      "metadata": {
        "id": "u_KzB9X-BYH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import skimage.measure\n",
        "\n",
        "\n",
        "img_transformed = np.copy(img)\n",
        "\n",
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QHbJKpQaBJD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformed = skimage.measure.block_reduce(img_transformed, (2,2), np.max)\n",
        "\n",
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XVFt1epVBvew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KKqdPJBCU_E"
      },
      "source": [
        "## **Secci√≥n IX**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Redes convolucionales\n",
        "\n",
        "**Spoiler:** Nuevamente, intentemos escalar posibles resultados al tener muchos filtros dentro de una red neuronal.\n",
        "\n",
        "Para ello, crearemos un modelo de red neuronal convolucional profunda, que utilice, precisamente, convoluciones en sus capas.\n",
        "\n",
        "Nos basaremos en un modelo LeNet5 propuesto por un gran investigador, Yann LeCun:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg\" width=\"60%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "WCO2eFvsCOVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential([\n",
        "\n",
        "    # First conv layer + subsampling\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second conv layer + subsampling\n",
        "    # TODO. Conv2D -> 256, (3, 3), ReLU\n",
        "    # TODO. MaxPool\n",
        "\n",
        "    # Third layer (flatten)\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fourth layer (dense)\n",
        "    # TODO. Dense -> 128, ReLU\n",
        "\n",
        "    # Fifth layer (output)\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "stCt0xNzzk_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Q85XFofVzskY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(training_images, training_labels, epochs=2)"
      ],
      "metadata": {
        "id": "ZwGZ6QBgz7Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "6Uxhd3HVz88g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_index = random.randint(0, 10000 - 1)\n",
        "\n",
        "plt.imshow(test_images[test_index], cmap='viridis')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "input_image = np.reshape(test_images[test_index], (1, 28, 28, 1))\n",
        "prediction = cnn_model.predict(input_image)\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "MXzIcx4Kz-b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsmVIiyTE51p"
      },
      "source": [
        "**¬°Felicidades! Has implementado y entrenado exitosamente tu modelo para clasificar algunas im√°genes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reto:** ¬øPuedes mejorar a√∫n m√°s el modelo?\n",
        "\n",
        "Te recomiendo explorar lo siguiente:\n",
        "- Modifica el n√∫mero de capas y par√°metros de convoluci√≥n por capa\n",
        "- Modifica el n√∫mero de √©pocas de entrenamiento\n",
        "- Explora resultados con otros conjuntos de datos\n",
        "- ¬øExportar modelos entrenados? Ojo: https://www.tensorflow.org/guide/keras/save_and_serialize?hl=es-419"
      ],
      "metadata": {
        "id": "8U1tdrMYlDen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Para resolver la tarea, el reto es:** Mejor accuracy obtenido en la clase.\n",
        "\n",
        "**Puedes explorar:**\n",
        "- El n√∫mero de capas.\n",
        "- Las √©pocas de entrenamiento.\n",
        "- Las funciones de activaci√≥n.\n",
        "- Investigar otras capas."
      ],
      "metadata": {
        "id": "QKp_PZ_NDqbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2023. <br>\n",
        "> Puedes contactarme a trav√©s de Insta ([@rodo_ferro](https://www.instagram.com/rodo_ferro/)) o Twitter ([@rodo_ferro](https://twitter.com/rodo_ferro))."
      ],
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      }
    }
  ]
}